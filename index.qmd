---
# title: "hallazgos imagenes epf"
# author: "Javiera Preuss"
format:
  revealjs:
    auto-stretch: false
    margin: 0
    slide-number: true
    scrollable: true
    preview-links: auto
    page-layout: custom
    logo: imagenes/logo_portada2.png
    css: ine_quarto_styles.css
    chalkboard: 
      boardmarker-width: 20
      buttons: false
    # footer: <https://quarto.org>
engine: knitr
---

#


<!---
# TODO: this does not work
 ![](imagenes/logo_portada2.png){.center style="width: 20%;"}   
--->

[]{.linea-superior} 
[]{.linea-inferior} 

<!---
 <img src="imagenes/logo_portada2.png" style="width: 20%"/>  
--->

<img src="imagenes/logo_portada2.png" width="20%"/>  


[**Prueba de conceptos: detecci√≥n de texto manuscrito en cuestionario gastos diarios EPF**]{.big-par .center-justified}

[**√Årea de Ciencia de Datos**]{.medium-par.center-justified}

[**Unidad de Gobierno de Datos**]{.small-par.center-justified}

[**Junio 2025**]{.big-par .center-justified}


## Contenidos  

- Contexto üìÑü§î

- Metodolog√≠as aplicadas ‚öôÔ∏èüî®

- Conclusiones üöÄ


## Contexto 

:::{.incremental .medium-par}

- En reuniones pasadas, se presentaron 4 problem√°ticas con el cuadernillo de gastos diarios:
  
  1. Automatizaci√≥n de descarga de boletas de supermercados
  
  2. Detecci√≥n de informaci√≥n escrita de boletas (nombre establecimiento, n√∫mero boleta, RUT, monto)
  
  3. Detecci√≥n de texto manuscrito de gastos diarios
  
  4. Identificaci√≥n de n√∫mero en cuadrado *d√≠a sin gasto*/*d√≠a sin registro*

:::


## Metodolog√≠as aplicadas (1/6)

:::{.incremental .medium-par}

1. Automatizaci√≥n de descarga de boletas de supermercados: 
  
  - Se intent√≥ realizar un scraping a las p√°ginas de los supermercados, pero estos conten√≠an captchas de compleja soluci√≥n
  
    [<img src="imagenes/plots/captcha1.jpg" width="35%"/>]{.center}
  
  - Si bien investigaron alternativas para responder estos captchas, algunas de las soluciones parciales involucraban uso de tecnolog√≠a de inteligencia artificial de pago
    
:::


## Metodolog√≠as aplicadas (2/6)

:::{.incremental .medium-par}

- Para los puntos 2, 3 y 4, el foco principal es poder identificar el texto presente en la imagen

  [<img src="imagenes/plots/cuadernillo1.jpg" width="70%"/>]{.center}

- Antes de dise√±ar un flujo de recorte de im√°genes, se realizaron pruebas de detecci√≥n de texto con modelos preentrenados.

  - Estos modelos de *deep learning* poseen arquitecturas complejas que procesan la imagen, identifican patrones y posteriormente construyen el texto (visi√≥n computacional y post-procesamiento NLP).
  
    [<img src="imagenes/plots/trocr.jpg" width="80%"/>]{.center}

:::


## Metodolog√≠as aplicadas (3/6)

:::{.incremental .medium-par}

- Los modelos utilizados para la prueba de conceptos son: 

  | Modelo | Espa√±ol| Resultado prueba | Link |
  |---|---|----|---|
  | Paquete easyocr*|‚úîÔ∏è| Detecci√≥n num√©rica: ‚ùå<br/> Detecci√≥n palabras: ‚ùå |[Link repo](https://github.com/JaidedAI/EasyOCR) |
  | microsoft/trocr-base-printed |üü°Ô∏è| Detecci√≥n num√©rica: ‚ùå<br/> Detecci√≥n palabras:  ‚ùå| [Link hugginface](https://huggingface.co/microsoft/trocr-base-printed)|
  | Paquete PaddleOCR*|‚úîÔ∏è| Detecci√≥n num√©rica: ‚ùå <br/> Detecci√≥n palabras: ‚ùå |[Link repo](https://github.com/PaddlePaddle/PaddleOCR)|
  | qantev/trocr-base-spanish|‚úîÔ∏è| Detecci√≥n num√©rica: üü° <br/> Detecci√≥n palabras:  ‚ùå| [Link hugginface](https://huggingface.co/qantev/trocr-base-spanish)|
  | qantev/trocr-large-spanish|‚úîÔ∏è| Detecci√≥n num√©rica: üü° <br/> Detecci√≥n palabras:  üü° | [Link hugginface](https://huggingface.co/qantev/trocr-large-spanish)|

- Se utiliz√≥ un set de 28 im√°genes, las cuales est√°n compuestas de n√∫meros, fechas y frases.

:::



## Metodolog√≠as aplicadas (4/6)

Ejemplos de detecci√≥n **num√©rica** con modelos base y large de TrOCR:

:::: {layout-ncol=2 .medium-par}

:::{.fragment .medium-par}

<img src="imagenes/plots/num_3.jpg" width="85%" />

<img src="imagenes/plots/num_4.jpg" width="85%" />

:::

:::fragment

<img src="imagenes/plots/num_1.jpg" width="85%" />

<img src="imagenes/plots/num_2.jpg" width="85%" />
:::

::::


## Metodolog√≠as aplicadas (5/6)

Ejemplos de detecci√≥n de **fechas** con modelos base y large de TrOCR:

:::: {layout-ncol=2 .medium-par}

:::{.fragment .medium-par}

<img src="imagenes/plots/fecha_1.jpg" width="80%" />

<img src="imagenes/plots/fecha_2.jpg" width="80%" />


:::

:::fragment
<img src="imagenes/plots/fecha_3.jpg" width="80%" />
:::

::::


## Metodolog√≠as aplicadas (6/6)

Ejemplos de detecci√≥n de **palabras** con modelos base y large de TrOCR:

:::: {layout-ncol=2 .medium-par}

:::{.fragment .medium-par}

<img src="imagenes/plots/palabras_1.jpg" width="85%" />

<img src="imagenes/plots/palabras_2.jpg" width="85%" />

:::

:::fragment

<img src="imagenes/plots/palabras_3.jpg" width="85%" />

<img src="imagenes/plots/palabras_4.jpg" width="85%" />

<img src="imagenes/plots/palabras_5.jpg" width="85%" />
:::

::::



## Finetuning modelos (1/4)

:::{.incremental .medium-par}

- Se realiz√≥ un finetuning para los modelos *qantev/trocr-base-spanish* y *qantev/trocr-large-spanish*, utilizando un set de 50 im√°genes etiquetadas

  [<img src="imagenes/plots/img_etiquetadas.jpg" width="90%"/>]{.center}

- Se logr√≥ detectar correctamente el 24% del set de entrenamiento para el modelo *base.*
  
  - El modelo *large* no obtuvo una mejora significativa en comparaci√≥n al *base*
  
  <!-- [<img src="imagenes/plots/pred_train.jpg" width="90%"/>]{.center} -->

:::

## Finetuning modelos (2/4)

:::{.incremental .medium-par}

- Al evaluar la predicci√≥n en el set 28 im√°genes iniciales, se obtuvo una disminuci√≥n del desempe√±o en caracteres num√©ricos y una leve mejora en palabras:

  [<img src="imagenes/plots/pred_num.jpg" width="90%"/>]{.center}


:::

## Finetuning modelos (3/4)

:::{.incremental .medium-par}

- Fechas:
[<img src="imagenes/plots/pred_fechas.jpg" width="100%"/>]{.center}

:::

## Finetuning modelos (4/4)

:::{.incremental .medium-par}

- Palabras:
[<img src="imagenes/plots/pred_palabras.jpg" width="95%"/>]{.center}

:::



## Conclusiones üöÄ{.medium-par}

::: incremental

- Si bien los modelos preentrenados funcionan bien detectando caracteres num√©ricos, estos no logran identificar correctamente las letras.

- Al realizar un _fine-tuning_ con 50 im√°genes, se observan leves mejoras en la identificaci√≥n de palabras, pero disminuye el rendimiento en la detecci√≥n de caracteres num√©ricos. 

- Para que el modelo logre captar de forma certera el texto, es necesario tener m√∫ltiples tipos de fuentes manuscritas etiquetadas con texto alfanum√©rico.

  - Se requieren al menos 1000 im√°genes para poder entrenar y evaluar el modelo 
    - A priori no hay garant√≠a de que sea bueno generalizando 

- En base a lo observado, si bien se podr√≠a brindar una soluci√≥n para la problem√°tica 4 (identificaci√≥n num√©rica de d√≠a sin gastos o registros), hay que evaluar el costo y beneficio que tendr√≠a la implementaci√≥n.

:::

#

[]{.linea-superior} 
[]{.linea-inferior} 


<img src="imagenes/logo_portada2.png" width="20%"/>  


[**Prueba de conceptos: detecci√≥n de texto manuscrito en cuestionario gastos diarios EPF**]{.big-par .center-justified}

[**√Årea de Ciencia de Datos**]{.medium-par.center-justified}

[**Unidad de Gobierno de Datos**]{.small-par.center-justified}

[**Junio 2025**]{.big-par .center-justified}

